{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dual SVM = 對偶 SVM\n",
    "\n",
    "SVM 可以利用 Feature Transform $ \\Phi $, 將原本的 $ x_n \\in \\Re^d $ 變成 $ z_n \\in \\Re^{\\tilde{d}} $ \n",
    "\n",
    "$ \\begin{bmatrix} b \\\\ w \\end{bmatrix} \\leftarrow QP(Q,p,A,c) $\n",
    "\n",
    "QP with $ \\tilde{d} + 1 $ variables and N constraints.  \n",
    "當 $ \\tilde{d} $ 很大時，甚至是 $ \\infty $ 時如何控制？\n",
    "\n",
    "> Goal: SVM without dependence on $ \\tilde{d} $\n",
    "\n",
    "如何將左邊的 Original SVM 轉換成右邊的 'Equivalent' SVM\n",
    "\n",
    "|...Original SVM...|...Equivalent SVM...|\n",
    "|-|-|\n",
    "|(convex) QP of|(convex) QP of|\n",
    "|$ \\tilde{d} + 1 $ variables| N variables |\n",
    "|N constraints|N+1 constraints|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 本章使用到深入的數學，不會一一說明，有些是用 CLAIM::: 的方式帶過。\n",
    "\n",
    "### Lagrange Multiplier\n",
    "\n",
    "Regularization by Constrained-Minimizing $ E_{in} $:\n",
    "\n",
    "$$ \\min_w E_{in}\\big( w \\big) \\ s.t. \\ w^T w \\le C $$\n",
    "\n",
    "利用 Lagrange Multiplier 轉換成如下的問題，沒有 s.t. (such that)...\n",
    "\n",
    "$$ \\min_w E_{aug}\\big( w \\big) = E_{in}\\big( w \\big) + \\frac{\\lambda}{N} w^T w $$\n",
    "\n",
    "在原本 Regularization，是將 $ \\lambda $ 作為使用者輸入。  \n",
    "在 Dual-SVM 這裡，我們會將 $ \\alpha ( \\lambda ) $ 當成一個變數，然後去解最佳化問題。\n",
    "\n",
    "How many $ \\lambda $ as variables? N (one per constraint)\n",
    "\n",
    "> 在 SVM 中，通常把 Lagrange Multiplier 叫做 alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Point: Constrained to Un-constrained\n",
    "\n",
    "$ min_{b,w} \\ \\ \\frac{1}{2} w^T w $\n",
    "\n",
    "$ s.t. \\ \\ y_n ( w^T z_n + b ) \\ge 1 $, for n = 1,2,...,N\n",
    "\n",
    "定義一個 Lagrange Function:\n",
    "\n",
    "$$ \\mathcal{L} (b,w,\\alpha) = \\underbrace{\\frac{1}{2} w^T w}_{\\text{objective}} + \\sum_{n=1}^N \\alpha_n \\big( \\underbrace{ 1 - y_n ( w^T z_n + b ) }_{\\text{constraint}} \\big) $$\n",
    "\n",
    "CLAIM:::  \n",
    "每一組 b,w 都放到 Lagrange Function 中，調整 alpha 值找到 max $ \\mathcal{L} (b,w,\\alpha) $\n",
    "\n",
    "$$ SVM \\equiv \\min_{b,w} \\Big( max_{all\\ \\alpha_n \\ge 0} \\mathcal{L} \\big( b,w,\\alpha \\big) \\Big) $$\n",
    "\n",
    "上述的 min( max(.) ) 變化，可以將 \"such that\" 條件放入 函數 L 中，函數L與原來 min ~ s.t. ~ 的效果相同，因為：\n",
    "\n",
    "先看 $ \\alpha_n \\big( 1 - y_n ( w^T z_n + b ) \\big)  $ 的 constraint 部分:\n",
    "\n",
    "- 不好的 (b,w): 違反了 $ y_n ( w^T z_n + b ) \\ge 1 $，再經過 alpha 乘以正值，最大化 max 後會趨近 $ \\infty $\n",
    "- 好的 (b,w): alpha 乘以正值，最大化 max 後會是 $ \\frac{1}{2} w^T w $\n",
    "\n",
    "經過 max(.) 的過程，在由 $ \\min_{b,w} \\Big( \\cdots \\Big) $ 選出小的，就會是 $ \\min_{b,w} \\frac{1}{2} w^T w $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lagrange Dual Problem\n",
    "\n",
    "for any fixed $ \\alpha' $ with all $ \\alpha_n' \\ge 0 $,\n",
    "\n",
    "$$ \\min_{b,w} \\Big( \\max_{all \\ \\alpha_n \\ge 0} \\mathcal{L}(b,w,\\alpha) \\Big) \\ge \\min_{b,w} \\mathcal{L} \\big( b, w, \\alpha' \\big) $$\n",
    "\n",
    "because max $ \\ge $ any.\n",
    "\n",
    "for best $ \\alpha' \\ge 0 $ on RHS,\n",
    "\n",
    "$$ \\min_{b,w} \\Big( \\max_{all \\ \\alpha_n \\ge 0} \\mathcal{L}(b,w,\\alpha) \\Big) \\ge \\underbrace{\\max_{all \\ \\alpha_n' \\ge 0} \\Big( \\min_{b,w} \\mathcal{L} \\big( b, w, \\alpha' \\big) \\Big)}_{\\text{Lagrange Dual Problem}} $$\n",
    "\n",
    "because BEST is one of ANY\n",
    "\n",
    "這樣把 max ~ min 互換，並得到 大於或等於 的關係，就叫 : Lagrange dual problem.\n",
    "\n",
    "如果可以解決 Lagrange dual problem，就可以得到原來問題的 下限。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong Duality of Quadratic Programming\n",
    "\n",
    "$$ \n",
    "\\underbrace{ \\min_{b,w} \\Big( \\max_{all \\ \\alpha_n \\ge 0} \\mathcal{L}(b,w,\\alpha) \\Big) }_{\\text{equiv. to original (primal) SVM}}\n",
    "\\ge\n",
    "\\underbrace{\\max_{all \\ \\alpha_n \\ge 0} \\Big( \\min_{b,w} \\mathcal{L} \\big( b, w, \\alpha \\big) \\Big)}_{\\text{Lagrange Dual}} \n",
    "$$\n",
    "\n",
    "$ \\ge $ : 的關係在 最佳化 上叫 weak duality\n",
    "\n",
    "數學上發現，如果滿足以下條件，可以達成 QP 問題的 強對偶 Strong Duality \"=\" 相等關係:\n",
    "\n",
    "- Convex Primal 凸函數\n",
    "- feasible Primal 由解的函數, 存在某組 (w,b) 讓資料可分\n",
    "- linear constraints\n",
    "\n",
    "滿足以上條件，叫做 constraint qualification。當使用 QP 解決 SVM 問題時，正好滿足以上條件。\n",
    "\n",
    "所以上述 Primal-Dual optimal problem, 正好有某組 $ (w,b,\\alpha) $ ，對於左邊的式子是最佳解，對右邊的式子也是最佳解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving Lagrange Dual: Simplifications\n",
    "\n",
    "$$\n",
    "\\max_{all \\ \\alpha_n \\ge 0}\n",
    "\\Big(\n",
    "\\min_{b,w} \n",
    "\\underbrace{\n",
    "  \\frac{1}{2} w^T w +\n",
    "  \\sum_{n=1}^N \\alpha_n \\big( 1 - y_n (w^T z_n + b) \\big)\n",
    "}_{\\mathcal{L}(b,w,\\alpha)}\n",
    "\\Big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inner problem 'unconstrained', at optimal (梯度為零, 對 b 做偏微分):\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial b} \\mathcal{L}(b, w, \\alpha) = 0 = - \\sum_{n=1}^N \\alpha_n y_n\n",
    "$$\n",
    "\n",
    "No loss of optimality if solving with constraint $ \\sum_{n=1}^N \\alpha_n y_n = 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b can be removed\n",
    "\n",
    "$$\n",
    "\\max_{all \\ \\alpha_n \\ge 0, \\sum y_n \\alpha_n = 0}\n",
    "\\Big(\n",
    "\\min_{b,w} \n",
    "\\underbrace{\n",
    "  \\frac{1}{2} w^T w +\n",
    "  \\sum_{n=1}^N \\alpha_n \\big( 1 - y_n (w^T z_n) \\big) -\n",
    "  \\underbrace{\\sum_{n=1}^N \\alpha_n y_n \\times b}_{\\text{This is ZERO!}}\n",
    "}_{\\mathcal{L}(b,w,\\alpha)}\n",
    "\\Big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去除 b 後，式子變成:\n",
    "\n",
    "$$\n",
    "\\max_{all \\ \\alpha_n \\ge 0, \\sum y_n \\alpha_n = 0}\n",
    "\\Big(\n",
    "\\min_{w} \n",
    "  \\frac{1}{2} w^T w +\n",
    "  \\sum_{n=1}^N \\alpha_n \\big( 1 - y_n (w^T z_n) \\big)\n",
    "\\Big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inner problem 'unconstrained', at optimal (梯度為零, 對 w 做偏微分):\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial w_i} \\mathcal{L}(b, w, \\alpha) = 0 = w_i - \\sum_{n=1}^N \\big( \\alpha y_n z_n \\big)_i\n",
    "$$\n",
    "\n",
    "No loss of optimality if solving with constraint (用向量形式表示) : $ w = \\sum_{n=1}^N \\alpha_n y_n z_n $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再代入式子變成:\n",
    "\n",
    "$$\n",
    "\\max_{all \\ \\alpha_n \\ge 0, \\sum y_n \\alpha_n = 0, w = \\sum \\alpha_n y_n z_n }\n",
    "\\Big(\n",
    "\\min_{w} \n",
    "  \\frac{1}{2} w^T w +\n",
    "  \\sum_{n=1}^N \\big( \\alpha_n \\big) - w^T w\n",
    "\\Big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\max_{all \\ \\alpha_n \\ge 0, \\sum y_n \\alpha_n = 0, w = \\sum \\alpha_n y_n z_n }\n",
    "\\Big(\n",
    "\\min_{w} \n",
    "  - \\frac{1}{2} w^T w +\n",
    "  \\sum_{n=1}^N \\big( \\alpha_n \\big)\n",
    "\\Big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\max_{all \\ \\alpha_n \\ge 0, \\sum y_n \\alpha_n = 0, w = \\sum \\alpha_n y_n z_n }\n",
    "\\Big(\n",
    "  - \\frac{1}{2} \\Big\\Vert \\sum_{n=1}^N \\alpha_n y_n z_n \\Big\\Vert^2 +\n",
    "  \\sum_{n=1}^N \\alpha_n\n",
    "\\Big)\n",
    "$$\n",
    "\n",
    "如此式子中已經不再出現 w\n",
    "\n",
    "如此就是在條件 $ \\sum y_n \\alpha_n = 0, w = \\sum \\alpha_n y_n z_n $ 之下，去找到最大的 $ \\alpha_n $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KKT Optimality Conditions\n",
    "\n",
    "$$\n",
    "\\max_{all \\ \\alpha_n \\ge 0, \\sum y_n \\alpha_n = 0, w = \\sum \\alpha_n y_n z_n }\n",
    "\\Big(\n",
    "  - \\frac{1}{2} \\Big\\Vert \\sum_{n=1}^N \\alpha_n y_n z_n \\Big\\Vert^2 +\n",
    "  \\sum_{n=1}^N \\alpha_n\n",
    "\\Big)\n",
    "$$\n",
    "\n",
    "Lagrange 對偶的簡化版問題。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if primal-dual optimal $ (b, w, \\alpha) $, 會滿足以下條件:\n",
    "\n",
    "- 1 ): primal feasible 原來的條件: $ y_n ( w^T z_n + b ) \\ge 1 $\n",
    "- 2 ): dual feasible: $ \\alpha_n \\ge 0 $\n",
    "- 3 ): dual inner optimal: $ \\sum y_n \\alpha_n = 0, \\ \\ w = \\sum \\alpha_n y_n z_n $\n",
    "- 4 ): primal-inner optimal ( at optimal all 'Lagrange terms' disappear ), also called Complimentary Slackness. alpha or (1-y...) is zero:\n",
    "\n",
    "$$ \\alpha_n \\big( 1 - y_n ( w^T z_n + b ) \\big) = 0 $$\n",
    "\n",
    "這些條件是 KKT conditions (Karush-Kuhn-Tucker), necessary for optimality ( & suffucient here )\n",
    "\n",
    "will use KKT to solve (b,w) from optimal alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual Formulation of SVM\n",
    "\n",
    "上面式子是 max 最大化，為了轉換成 min 最小化問題，乘以 -1；並將平方展開。  \n",
    "把條件分開寫下。\n",
    "\n",
    "$$\n",
    "\\min_{\\alpha} \\ \\ \\frac{1}{2} \\sum_{n=1}^N \\sum_{m=1}^N \\alpha_n \\alpha_m y_n y_m z_n^T z_m - \\sum_{n=1}^N \\alpha_n\n",
    "$$\n",
    "\n",
    "Subject to:\n",
    "\n",
    "#### 1. dual inner optimal\n",
    "\n",
    "$$\n",
    "\\sum_{n=1}^N y_n \\alpha_n = 0\n",
    "$$\n",
    "\n",
    "#### 2. dual feasible\n",
    "\n",
    "all $ \\alpha_n \\ge 0 $ for n = 1,2,3,...,N\n",
    "\n",
    "如此就是一個 (Convex) QP of N variables & N+1 constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual SVM with QP Solver\n",
    "\n",
    "optimal $ \\alpha \\leftarrow QP( Q_{Dual}, p, A, c) $\n",
    "\n",
    "Q: 二次項係數  \n",
    "p: 一次項係數  \n",
    "A: 條件係數  \n",
    "c: 條件的常數  \n",
    "\n",
    "$$ min_{\\alpha} \\frac{1}{2} \\alpha^T Q_D \\alpha + p^T \\alpha $$\n",
    "\n",
    "$$ \\text{subject to } a_i^T \\alpha \\ge c_i, \\text{ for i=1,2,... } $$\n",
    "\n",
    "$ q_{n,m} = y_n y_m z_n^T z_m $\n",
    "\n",
    "$ p = \\vec{-1}_N $, 長度 N 的內含都是 -1 的向量。\n",
    "\n",
    "$ y_n \\alpha_n = 0 $ 的條件: $ a = y, c = 0 $ 再加上 $ a = -y, c = 0 $\n",
    "\n",
    "$ \\alpha_n \\ge 0 $ 的條件: $ a_n^T = \\text{ n-th unit direction }, c_n = 0 $\n",
    "\n",
    "> Many solvers treat equality (同時大於小於) & bound (最小值) constraints specially for numerical stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual SVM with Special QP Solver\n",
    "\n",
    "$ q_{n,m} = y_n y_m z_n^T z_m $, often none-zero.\n",
    "\n",
    "If N = 30,000, a dense $ Q_D $ (N by N symmetric) takes $ \\gt $ 3G RAM.\n",
    "\n",
    "需要用一些特殊的 solver 才可避免 Q 太大的問題:  \n",
    "\n",
    "- not storing whole $ Q_D $  \n",
    "- utilizing special constraints properly.\n",
    "\n",
    "才可能處理 large N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal (b,w) - Get b,w\n",
    "\n",
    "$$ w = \\sum \\alpha_n y_n z_n $$\n",
    "\n",
    "$ \\alpha_n \\big( 1 - y_n(w^T z_n + b) \\big) = 0 $，所以找到任一個 $ \\alpha_n \\gt 0 $ 就可得 (y是 +1/-1):\n",
    "\n",
    "$$ b = y_n - w^T z_n $$\n",
    "\n",
    "> 如果 $ \\alpha_n \\gt 0 $ 就代表對應的 $ 1 - y_n(w^T z_n + b) $ 在邊界上，是 Support Vector (SV)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vectors\n",
    "\n",
    "- SV (Support Vector) : $ \\alpha_n \\gt 0 $ 的點，在邊界上\n",
    "- SV candidates : 在邊界上，$ \\alpha_n $ 不一定大於零。\n",
    "\n",
    "#### Support Vector 的重要性\n",
    "\n",
    "- only SV needed to compute: $ w = \\sum_{n=1}^N \\alpha_n y_n z_n = \\sum_{SV} \\alpha_n y_n z_n $\n",
    "- only SV needed to compute: $ b = y_n - w^T z_n \\text{ with any SV } (z_n, y_n) $\n",
    "\n",
    "> SVM: Learn fattest hyperplane by identifying Support Vectors with dual optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual Hard-Margin SVM\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min_{\\alpha} \\ \\ & \\frac{1}{2} \\alpha^T Q_D \\alpha - 1^T \\alpha \\\\\n",
    "\\text{such that } & y^T \\alpha = 0 \\\\\n",
    "                  & \\alpha_n \\ge 0 \\text{ for } n = 1, \\cdots, N\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "注意 $ Q_D $ 的計算仍是 $ O(\\tilde{d}), q_{n,m} = y_n y_m z_n^T z_m $,  \n",
    "如何避開這個計算，要依靠不同的 kernel."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
