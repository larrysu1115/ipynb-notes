{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender System\n",
    "\n",
    "- data: how 'many users' have rated 'some movies'\n",
    "- skill: predict how a user would rate an unrated movie.\n",
    "\n",
    "如 N 個 users 對 M 部 movies 做評分 rating r.  \n",
    "使用者:n 對 電影:m 的 評分:r\n",
    "\n",
    "$$\n",
    "\\mathcal{D}_m = \\Big\\{ \\big( \\tilde{x}_n = (n), y_n = r_{nm} \\big) \\Big\\}\n",
    "$$\n",
    "\n",
    "abstract feature $ \\tilde{x}_n = (n) $ : 使用者只是一個編號ID, 如何從這樣的 [抽象特徵] 資料學習到偏好?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Vector Encoding of Categorical Feature\n",
    "\n",
    "Categorical Features: \n",
    "\n",
    "- $ \\tilde{x}_n = (n) $ : User IDs, such as 2412,5123,6872; 沒有特殊意義，只是個編號\n",
    "- Blood Type: A, B, AB, O\n",
    "- Programming Language: C, Golang, Java, Python, ...\n",
    "\n",
    "Many ML model operate on numerical features\n",
    "\n",
    "- linear models\n",
    "- extended linear models such as NNet\n",
    "- Decision Tree can operate on categorical feature.\n",
    "\n",
    "NEED: encoding (transform) **from categorical to numerical**\n",
    "\n",
    "Binary Vector encoding:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} 1\\\\0\\\\0\\\\0 \\end{bmatrix}, \\ \\ \n",
    "B = \\begin{bmatrix} 0\\\\1\\\\0\\\\0 \\end{bmatrix}, \\ \\ \n",
    "AB = \\begin{bmatrix} 0\\\\0\\\\1\\\\0 \\end{bmatrix}, \\ \\ \n",
    "O = \\begin{bmatrix} 0\\\\0\\\\0\\\\1 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction from Encoded Vector\n",
    "\n",
    "$$\n",
    "\\mathcal{D}_m = \\Big\\{ \\big( \\tilde{x}_n = BinaryVectorEncoding(n), y_n = r_{nm} \\big) \\Big\\}\n",
    "$$\n",
    "\n",
    "? 問號表示沒有評分\n",
    "\n",
    "$$\n",
    "\\mathcal{D}_m = \\Big\\{ \\big( \\tilde{x}_n = BinaryVectorEncoding(n), y_n = \n",
    "\\begin{bmatrix}\n",
    "r_{n1} \\\\ ? \\\\ ? \\\\ r_{n4}  \\\\ r_{n5} \\\\ \\vdots \\\\ r_{nM}\n",
    "\\end{bmatrix}\n",
    "\\big) \\Big\\}\n",
    "$$\n",
    "\n",
    "idea: try feature extraction using $ N-\\tilde{d}-M $ NNet without all $ x_0^{(\\mathcal{l})} $ (為了簡單起見忽略常數項)\n",
    "\n",
    "因為 x 是只有一項為 1, 其他項為 0 的向量， NNet 中的 tanh 節點可以直接用 linear, 還是能夠表達單一 x項 的權重。\n",
    "\n",
    "![img](imgs/c215-matrix-fact-nnet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matrix $ V^T $ of size $ N \\times \\tilde{d} $\n",
    "\n",
    "matrix $ W $ of size $ \\tilde{d} \\times M $\n",
    "\n",
    "hypothesis: \n",
    "\n",
    "$ h(x) = W^T_{M \\times \\tilde{d}} \\ V_{\\tilde{d} \\times N} \\vec{x}_{N \\times 1} $\n",
    "\n",
    "per-user output:\n",
    "\n",
    "$ h(x_n) = W^T v_n $, where $ v_n $ is n-th column of V, 因为 $ x_n $ 只有一個項是 1, 其他是 0.\n",
    "\n",
    "linear network for recommender system: learn V and W."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Network: Linear Model Per Movie\n",
    "\n",
    "linear network:\n",
    "\n",
    "$$\n",
    "h(x) = W^T \\underbrace{\\ V \\ x}_{\\Phi(x)}\n",
    "$$\n",
    "\n",
    "for m-th movie, just linear model: $ h_m(x) = w_m^T \\ \\Phi(x) $\n",
    "\n",
    "for every $ \\mathcal{D}_m $, want $ r_{nm} = y_n \\approx w_m^T v_n $\n",
    "\n",
    "$ E_{in} $ over all $ \\mathcal{D}_m $ with squared error measure: (user:n rated movie:m)\n",
    "\n",
    "$$\n",
    "E_{in} \\big( \\{ w_m \\}, \\{ v_n \\} \\big) =\n",
    "\\frac{1}{\\sum_{m=1}^M | D_m | }\n",
    "\\sum \\Big( r_{nm} - w_m^T v_n \\Big)^2\n",
    "$$\n",
    "\n",
    "linear network: transform and linear modelS jointly learned from all $ \\mathcal{D}_m $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Martix Factorization\n",
    "\n",
    "$$\n",
    "r_{nm} \\approx w_m^T v_n = v_n^T w_m \\iff R \\approx V^T W\n",
    "$$\n",
    "\n",
    "learning:\n",
    "\n",
    "- known rating\n",
    "- learned factors $ v_n $ and $ w_m $\n",
    "- unknown rating prediction\n",
    "\n",
    "similar modeling can be used for other abstract features.\n",
    "\n",
    "![img](imgs/c215-matrix-r.png)\n",
    "\n",
    "![img](imgs/c215-model-vis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization Learning\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min_{W,V} E_{in} \\big( \\{ w_m \\}, \\{ v_n \\} \\big) \\propto & \\sum_{\\text{user n rated movie m}} \\big( r_{nm} - w_m^T v_n \\big)^2 \\\\\n",
    "= & \\sum_{m=1}^M \\Big( \\sum_{(x_n, r_{nm}) \\in D_m} \\big( r_{nm} - w_m^T v_n \\big)^2 \\Big)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "two set of variables: can consider **alternating minimization**\n",
    "\n",
    "when $ v_n $ fixed, minimizing $ w_m \\equiv $ minimize $ E_{in} $ within $ D_m $\n",
    "\n",
    "- simply per-movie (per Dm) linear regression without $ w_0 $\n",
    "\n",
    "when $ w_m $ fixed, minimizing $ v_n $\n",
    "\n",
    "- per-user linear regression without $ v_0 $\n",
    "\n",
    "by symmetry between users/movies\n",
    "\n",
    "called **alternating least squares** algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating Least Squares\n",
    "\n",
    "STEP 1: initialize $ \\tilde{d} $ dimension vectors $ \\{ w_m \\}, \\{ v_n \\} $\n",
    "\n",
    "STEP 2: alternating optimization of $ E_{in} $: repeatedly\n",
    "\n",
    "STEP 2.a: optimize $ w_1, w_2, \\cdots, w_M $: update $ w_m $ by m-th-movie linear regression on $ \\{ (v_n, r_{nm}) \\} $\n",
    "\n",
    "STEP 2.b: optimize $ v_1, v_2, \\cdots, v_N $: update $ v_n $ by n-th-user linear regression on $ \\{ (w_m, r_{nm}) \\} $\n",
    "\n",
    "until converge.\n",
    "\n",
    "- initialize: usually just randomly.\n",
    "- converge: guaranteed as $ E_{in} $ decreases during alternating minimization\n",
    "\n",
    "Alternating Least Squares: the 'tango' dance between users/movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Autoencoder versus Matrix Factorization\n",
    "\n",
    "|x|Linear Autoencoder|Matrix Factorization|\n",
    "|-|-|-|\n",
    "|motivation   | special d-$\\tilde{d}$-d NNet | N-$\\tilde{d}$-M linear NNet |\n",
    "|error measure| squared on all $ x_{ni} $ | squared on known $ r_{nm} $ |\n",
    "|solution     | global optimal at eigenvectors of $ X^T X $ | local optimal via alternating least squares |\n",
    "|usefulness   | extract dimension-reduced features | extract hidden user/movie features |\n",
    "\n",
    "Linear Autoencoder $ \\equiv $ Special matrix factorization of complete X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
