{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression\n",
    "\n",
    "如何結合 L2-Regularized Linear Model 與 Kernel, 獲得 Analytic Solution for kernel ridge regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for any L2-regularized linear model\n",
    "\n",
    "$$\n",
    "\\min_w \\frac{\\lambda}{N} w^T w + \\frac{1}{N} \\sum_{n=1}^N err \\big( y_n, w^T z_n \\big)\n",
    "$$\n",
    "\n",
    "optimal $ w_{*} = \\sum_{n=1}^N \\beta_n z_n $\n",
    "\n",
    "for Regression with Squared Error:\n",
    "\n",
    "$$\n",
    "err \\big( y_n, w^T z_n \\big) = \\big( y - w^T z \\big)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Ridge Regression Problem\n",
    "\n",
    "$\n",
    "\\min_w \\frac{\\lambda}{N} w^T w + \\frac{1}{N} \\sum_{n=1}^N \\big( y_n - w^T z_n \\big)^2\n",
    "$\n",
    "\n",
    "optimal $ w_{*} = \\sum_{n=1}^N \\beta_n z_n $\n",
    "\n",
    "將 w 替換成 $ \\beta $, 就可以將問題變成 $ \\beta $ 的最佳化。 \n",
    "\n",
    "$$\n",
    "\\min_{\\beta} \\frac{\\lambda}{N} \\sum_{n=1}^N \\sum_{m=1}^N \\beta_n \\beta_m K(x_n, x_m) \n",
    "+ \\frac{1}{N} \\sum_{n=1}^N \\Big( y_n - \\sum_{m=1}^N \\beta_m  K(x_n,x_m) \\Big)^2 \\\\\n",
    "= \\frac{\\lambda}{N} \\beta^T K \\beta + \\frac{1}{N} \\big( \\beta^T K ^T K \\beta - 2 \\beta^T K^T y + y^T y \\big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving Kernel Ridge Regression\n",
    "\n",
    "$\n",
    "E_{aug}(\\beta) = \\frac{\\lambda}{N} \\beta^T K \\beta + \\frac{1}{N} \\big( \\beta^T K ^T K \\beta - 2 \\beta^T K^T y + y^T y \\big)\n",
    "$\n",
    "\n",
    "$\n",
    "\\nabla E_{aug}(\\beta) = \\frac{2}{N} \\big( \\lambda K^T I \\beta + K^T K \\beta - k^T y \\big) \\\\\n",
    "= \\frac{2}{N} K^T \\big( ( \\lambda I + K ) \\beta - y \\big)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "want $ \\nabla E_{aug} (\\beta) = 0 $ : one anayttic solution\n",
    "\n",
    "$$\n",
    "\\beta = \\big( \\lambda I + K \\big)^{-1} y\n",
    "$$\n",
    "\n",
    "- $ (...)^{-1} $ always exists for $ \\lambda \\gt 0 $, because K is positive semi-definite. (Mercer's condition)\n",
    "- time complexity: $ O(N^3) $ with simple dense matrix inversion\n",
    "\n",
    "Can now do non-linear regression 'easily'.\n",
    "\n",
    "![img](imgs/c206-linear-kernel-ridge-reg.jpg)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
