{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent\n",
    "\n",
    "Logistic Regression 中每次都需做所有點的梯度，可否隨機只抽一個點，將每次 iteration 的複雜度降低為 O(1) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Iteration:\n",
    "\n",
    "$$\n",
    "\\nabla E_{in}(w_t) = \\frac{1}{N} \\sum_{n=1}^N \\theta \\Big( -y_n w_t^T x_n \\Big) \\big( -y_n x_n \\big)\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_{t+1} = w_t - \\eta \\nabla E_{in}(w_t)\n",
    "$$\n",
    "\n",
    "試著移除複雜度 $ \\frac{1}{N} \\sum_{n=1}^N $, 將這個平均數看成是 在 n 中做 Uniform Choice 的 期望值 $ \\mathcal{E} $\n",
    "\n",
    "Stochastic Gradient: 隨機找一個點，算梯度。\n",
    "\n",
    "$ \\nabla_w err(w, x_n, y_n) $ with random n\n",
    "\n",
    "True Gradient:\n",
    "\n",
    "$ \\nabla_w E_{in}(w) = \\mathcal{E}_{\\text{random n}} \\nabla_w err(w, x_n, y_n) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient = True Gradient + Zero-Mean NOISE directions.\n",
    "\n",
    "IDEA: replace TRUE Gradient by STOCHASTIC Gradient\n",
    "\n",
    "After \"enough\" steps, average true gradient $ \\approx $ average stochastic gradient\n",
    "\n",
    "- 優: Simple and Cheaper computation\n",
    "- 優: Useful for BigData or Online Learning\n",
    "- 缺: less stable in nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD Logistic Regression:\n",
    "\n",
    "$ w_{t+1} \\leftarrow w_t + \\eta \\cdot \\theta \\big( -y_n w_t^T x_n \\big) (y_n x_n) $\n",
    "\n",
    "PLA:\n",
    "\n",
    "$ w_{t+1} \\leftarrow w_t + 1 \\cdot \\big[ y_n \\ne sign(w_t^T x_n) \\big]_{boolean} (y_n x_n) $\n",
    "\n",
    "SGD logistic regression $ \\approx $ 'SOFT' PLA\n",
    "\n",
    "PLA $ \\approx $ SGD logistic regression with $ \\eta = 1 $ when $ w_t^T x_n $ large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不容易決定何時停下，因為不再算平均梯度。通常就跑夠多的 t 次。\n",
    "\n",
    "$ \\eta = ? $ 如果 x in proper range，試試看 0.1126 "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
