{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radial Basis Function Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Kernel: $ K(x, x') = K(x,y) = \\exp \\big( - \\gamma \\Vert x - y \\Vert^2 \\big), \\text{ with } \\gamma \\ge 0 $\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "g_{SVM}(x) & = sign \\Big( \\sum_{SV} \\alpha_n y_n K(x_n, x) + b \\Big) \\\\\n",
    "           & = sign \\Big( \\sum_{SV} \\alpha_n y_n \\exp \\big( - \\gamma \\Vert x - x_n \\Vert^2 \\big) + b \\Big)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RBF 可看作是在一堆 SV, $ \\alpha $ 上，做線性組合求解\n",
    "\n",
    "- radial: 距離, SV 的點 x 與 中心:$x_n$ 的距離\n",
    "- basis function: 拿來做線性組合的係數: $ \\alpha_n, y_n $ \n",
    "\n",
    "拿到一個點 x, 看這個點與中心的距離，然後進行投票 y\n",
    "\n",
    "$ g_n(x) = y_n \\exp \\big( - \\gamma \\big\\Vert x - x_n \\big\\Vert^2 \\big) $\n",
    "\n",
    "再將所有點的結果合起來\n",
    "\n",
    "$$\n",
    "g_{SVM}(x) = sign \\Big( \\sum_{SV} \\alpha_n g_n(x) + b \\Big)\n",
    "$$\n",
    "\n",
    "結果是 linear aggregation of selected (SV) radial (半徑距離) hypothesis $g_n(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF Network hypothesis\n",
    "\n",
    "<img src=\"imgs/c214-rbf-network-hypo.png\" style=\"float:right;width:350px;\" >\n",
    "\n",
    "$\n",
    "h(x) = Output \\Big( \\sum_{m=1}^M \\beta_m \\ RBF(x, \\mu_m) + b \\Big)\n",
    "$\n",
    "\n",
    "centers: $ \\mu_m : $ SVM SVs $ x_m $\n",
    "\n",
    "(signed) votes: $ \\beta_m : \\alpha_m y_m $ from SVM Dual \n",
    "\n",
    "RBF: Gaussian\n",
    "\n",
    "Output: sign (binary classification)\n",
    "\n",
    "M = # of SVs\n",
    "\n",
    "**Learning**: given RBF and Output, decide: $ \\mu_m, \\beta_m $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF and Similarity\n",
    "\n",
    "kernel: similarity via Z-space inner product\n",
    "\n",
    "- governed by Mercer's condition.\n",
    "\n",
    "$ Poly(x, x') = (1 + x^T x')^2 $\n",
    "\n",
    "$ Gaussian(x, x') = \\exp \\big( - \\gamma \\Vert x - x' \\Vert^2 \\big) $\n",
    "\n",
    "RBF: similarity via X-space distance\n",
    "\n",
    "general similarity function between x and x':\n",
    "\n",
    "Neuron(x, x') = $ tanh( \\gamma x^T x' + 1) $\n",
    "\n",
    "DNASim(x, x') = $ EditDistance(x, x') $\n",
    "\n",
    "RBF Network: distance similariry-to-centers as feature transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full RBF Network\n",
    "\n",
    "$$\n",
    "h(x) = Output \\Big( \\sum_{m=1}^M \\beta_m \\ RBF(x, \\mu_m) + b \\Big)\n",
    "$$\n",
    "\n",
    "full RBF Network: M=N and each $ \\mu_m = x_m $\n",
    "\n",
    "physical meaning: each $ x_m $ influences similar x by $ \\beta_m $\n",
    "\n",
    "e.g. uniform influence with $ \\beta_m = 1 \\cdot y_m $, for binary classification.\n",
    "\n",
    "$$\n",
    "g_{uniform}(x) = sign \\Big( \\sum_{m=1}^N y_m \\exp \\big( - \\gamma \\Vert x - x_m \\Vert^2 \\big) \\Big)\n",
    "$$\n",
    "\n",
    "- aggregate each example's opinion subject to similarity.\n",
    "\n",
    "full RBF Network: lazy way to decide $ \\mu_m $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbor\n",
    "\n",
    "$$\n",
    "g_{uniform}(x) = sign \\Big( \\sum_{m=1}^N y_m \\exp \\big( - \\gamma \\Vert x - x_m \\Vert^2 \\big) \\Big)\n",
    "$$\n",
    "\n",
    "$ \\exp \\big( - \\gamma \\Vert x - x_m \\Vert^2 \\big) $ : 當 x 離 $ x_m $ 最近時候，會最大化影響力  \n",
    "maximum one often dominates the $ \\sum_m^N $ term\n",
    "\n",
    "使用最近的點 maximum exp(...) 的 $ y_m $, 而不用所有點的 voting,  \n",
    "selection instead of aggregation\n",
    "\n",
    "physical meaning:\n",
    "\n",
    "$ g_{nbor} \\big( x \\big) = y_m $, such that x closest to $ x_m $\n",
    "\n",
    "called nearest neighbor model.\n",
    "\n",
    "can uniformly aggregate k neighbors also: **k nearest neighbor**\n",
    "\n",
    "k nearest neighbor: also lazy but intuitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation by Full RBF Network\n",
    "\n",
    "full RBF Network for squared error regression:\n",
    "\n",
    "$$\n",
    "h(x) = Output \\Big( \\sum_{m=1}^N \\beta_m \\ \\ RBF(x, x_m) \\Big)\n",
    "$$\n",
    "\n",
    "將 Output 直接輸出，就是 linear regression on RBF-transformed data, 向量 $ z_n \\in \\mathcal{R}^N $\n",
    "\n",
    "$$\n",
    "z_n = \\Big[ RBF(x_n,x_1), \\ RBF(x_n,x_2), \\ \\cdots \\ , \\ RBF(x_n,x_N) \\Big] \\in \\mathcal{R}^N\n",
    "$$\n",
    "\n",
    "linear regression 公式解, optimal $ \\beta = \\big( Z^T Z \\big)^{-1} Z^T y \\iff Z^T Z $ is invertible}\n",
    "\n",
    "size of Z? $ Z_{N \\times N} $\n",
    "\n",
    "Z 是 symmetric square matrix, 當套用在 Gaussian RBF 時，有 theoretical fact: \n",
    "\n",
    "if $ x_n $ all different, Z with Gaussian RBF is invertible\n",
    "\n",
    "symmetric: $ Z = Z^T $\n",
    "\n",
    "$ \n",
    "\\begin{align}\n",
    "\\beta = & \\big( Z^T \\ Z \\big)^{-1} Z^T y \\\\\n",
    "      = & \\big( Z \\ Z \\big)^{-1} Z y \\\\\n",
    "      = & Z^{-1} \\  Z^{-1} \\  Z \\ y \\\\\n",
    "      = & Z^{-1} \\ y\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized RBF Network\n",
    "\n",
    "full Gaussian RBF Network for regression: $ \\beta = Z^{-1} y $\n",
    "\n",
    "$$\n",
    "g_{RBF} (x_1) = \\beta^T z_1 = y^T Z^{-1} \\big( \\text{ first column of Z } \\big) = \n",
    "y^T \n",
    "\\begin{bmatrix}\n",
    "1 \\\\ 0 \\\\ \\vdots \\\\ 0\n",
    "\\end{bmatrix}\n",
    "= y_1\n",
    "$$\n",
    "\n",
    "以此類推知道: $ g_{RBF} (x_n) = y_n $, 所以 $ E_{in} \\big( g_{RBF} \\big) = 0 $\n",
    "\n",
    "called exact interpolation for function approximation.\n",
    "\n",
    "but overfitting for learning.\n",
    "\n",
    "may use regularization, e.g. ridge regression for $ \\beta $ instead\n",
    "\n",
    "optimal $ \\beta = \\big( Z^T Z + \\lambda I \\big)^{-1} Z^T y $\n",
    "\n",
    "這個公式 $ Z = \\big[ Gaussian(x_n, x_m) \\big] = $ Gaussian SVM 中的 Kernel matrix K\n",
    "\n",
    "regularized full RBFNet: $ \\beta = \\big( Z^T Z + \\lambda I \\big)^{-1} Z^T y $ ...(對有限維度N, 做 regularization)\n",
    "\n",
    "kernel ridge regression: $ \\beta = \\big( K + \\lambda I \\big)^{-1} y $ ...(對無限多維度, 做 regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fewer Centers as Regularization\n",
    "\n",
    "$$\n",
    "g_{SVM}(x) = sign \\Big( \\sum_{SV} \\alpha_m y_m \\exp \\big( - \\gamma \\Vert x - x_m \\Vert^2 \\big) + b \\Big)\n",
    "$$\n",
    "\n",
    "只需要用 SVs\n",
    "\n",
    "next $ M \\ll N $ instead of M = N\n",
    "\n",
    "effect: regularization by constraining number of centers and voting weights.\n",
    "\n",
    "physical meaning of centers $ \\mu_m $ : prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good prototypes: Clustering Problem\n",
    "\n",
    "if $ x_1 \\approx x_2 $\n",
    "\n",
    "- no need both RBF(x, x1) and RBF(x, x2) in RBFNet\n",
    "- cluster x1 and x2 by one prototype $ \\mu \\approx x_1 \\approx x_2 $\n",
    "\n",
    "Clustering with prototype:\n",
    "\n",
    "- partition $ \\big\\{ x_n \\big\\} $ to disjoint sets $ S_1, S_2, \\cdots, S_M $\n",
    "- choose $ \\mu_m $ for each $ S_m $\n",
    "- $ \\big\\{ x_1, x_2 \\big\\} \\in S_m \\iff \\mu_m \\approx x_1 \\approx x_2 $\n",
    "\n",
    "cluster error with squared error measure:\n",
    "\n",
    "$$\n",
    "E_{in} \\big( S_1, \\cdots, S_M; \\ \\mu_1, \\cdots, \\mu_m \\big) = \\frac{1}{N} \\sum_{n=1}^N \\sum_{m=1}^M \\big[ x_n \\in S_m \\big]_{boolean}\n",
    "\\Vert x_n - \\mu_m \\Vert^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition Optimization\n",
    "\n",
    "with $ S_1, \\cdots, S_M $ being a partition of $ \\big\\{ x_n \\big\\} $,\n",
    "\n",
    "$$\n",
    "min_{\\big\\{S_1, \\cdots, S_M; \\ \\mu_1, \\cdots, \\mu_m \\big\\}}\n",
    "\\sum_{n=1}^N \\sum_{m=1}^M \\big[ x_n \\in S_m \\big]_{boolean}\n",
    "\\Vert x_n - \\mu_m \\Vert^2\n",
    "$$\n",
    "\n",
    "這是一個困難的組合最佳化問題，因為複合了兩個問題:\n",
    "\n",
    "- 哪些 x 分在一組 S ?\n",
    "- 每組 S 的中心 $ \\mu $ 如何決定?\n",
    "\n",
    "解決的方法，是將 $ \\mu $ 分別 fix 固定來處理:\n",
    "\n",
    "if $ \\mu_1, \\cdots, \\mu_m $ fixed, for each $ x_n $\n",
    "\n",
    "- $ big[ x_n \\in S_m \\big]_{boolean} $ : choose one and only one subset\n",
    "- $ \\Vert x_n - \\mu_m \\Vert^2 $ : distance to each prototype.\n",
    "\n",
    "optimal chosen subset $ S_m $ = the one with minimum $ \\Vert x_n - \\mu_m \\Vert^2 $\n",
    "\n",
    "如上確定分群 S, 再找每個群 S 的中心點 $ \\mu_m $\n",
    "\n",
    "if $ S_1, \\cdots, S_M $ fixed, just unconstrained optimization for each $ \\mu_m $\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mu_m} E_{in} = -2 \\sum_{n=1}^N\n",
    "\\big[ x_n \\in S_m \\big]_{boolean} \\big( x_n - \\mu_m \\big) =\n",
    "-2 \\Big( \\big( \\sum_{x_n \\in S_m} x_n \\big) - \\big| S_m \\big| \\ \\mu_m \\Big)\n",
    "$$\n",
    "\n",
    "optimal prototype $ \\mu_m $ = average of $ x_n $ within $ S_m $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Algorithm\n",
    "\n",
    "k prototypes\n",
    "\n",
    "STEP 0: choose k $ \\mu $ \n",
    "\n",
    "then repeat STEP 1~2, until converge\n",
    "\n",
    "STEP 1: optimize $ S_1, S_2, \\cdots, S_k $, each $ x_n $ partitioned using closest $ \\mu $\n",
    "\n",
    "STEP 2: optimize $ \\mu_1, \\mu_2, \\cdots, \\mu_k $, each $ \\mu_n $ computed from $ S_m $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF Network using k-means\n",
    "\n",
    "STEP 1: run k-Means with k=M to get $ \\big\\{ \\mu_m \\big\\} $\n",
    "\n",
    "STEP 2: construct transform $ \\Phi(x) $ from RBF (say, Gaussian) at $ \\mu_m $\n",
    "\n",
    "$$\n",
    "\\Phi(x) = \\big[ RBF(x, \\mu_1), \\ RBF(x, \\mu_2), \\ \\cdots, RBF(x, \\mu_M), \\  \\big]\n",
    "$$\n",
    "\n",
    "STEP 3: run linear model on $ \\Big\\{ \\big( \\Phi(x_n), y_n \\big) \\Big\\} $ to get $ \\beta $\n",
    "\n",
    "STEP 4: return $ g_{RBFNET} (x) = \\text{ LinearHypothesis } \\big( \\beta, \\Phi(x) \\big) $"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
