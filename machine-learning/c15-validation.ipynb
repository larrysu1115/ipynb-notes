{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many Model Learned\n",
    "\n",
    "Algorithm: { PLA, pocket, linear regression, logistic regression }\n",
    "\n",
    "T: { 100, 1000, 10000... }, iteration 跑多少次\n",
    "\n",
    "$ \\eta $: { 1, 0.01, 0.0001, ...}, 每步更新多少，如在 gradient decent 時\n",
    "\n",
    "$ \\Phi $: { linear, quadratic, poly-10, Legendre-Poly-10, ... } : Feature Transform 的方法\n",
    "\n",
    "$ \\Omega(w) $: { L2 Regularizer, L1 Regularizer, Symmetry Regularizer }\n",
    "\n",
    "$ \\lambda $: {0, 0.01, 1, ...}, Regularizer 的強度。\n",
    "\n",
    "> 各種選擇的組合，如何確定找出的 g 是好的？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection by best $ E_{test} $\n",
    "\n",
    "選出驗證資料 $ D_{val} $ ，然後在 m個 A:Alogrithm 中選擇出 $ \\min E_{test}(g_m) $ 的最佳解 $ g_m $\n",
    "\n",
    "Generalization Guarantee (finite-bin Hoeffding):\n",
    "\n",
    "$$ E_{out} \\big( g_m \\big) \\le E_{test} \\big( g_m \\big) + O \\big( \\sqrt{\\frac{\\log M}{N_{test}}} \\big) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set $ D_{val} $\n",
    "\n",
    "$ D \\to D_{train} \\cup D_{val} $ : 將原始資料 D 分成 training (size:N-K) 和 validation (size:K) 兩部份。\n",
    "\n",
    "由 $ D_{train} $ 送入 $ A_m $ 中獲得 m 個 $ E_{val} $, 選擇 validation error 最小的 $ g^-_m $ ，再用 全部的 D 跑一次獲得 $ g_m $\n",
    "\n",
    "$$ E_{out}(g_{m}) \\le E_{out}(g^-_m) \\le E_{val}(g^-_m) + O \\big( \\sqrt{\\frac{\\log M}{K}} \\big)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dilemma about K\n",
    "\n",
    "$$ E_{out}(g) \\approx E_{out}(g^-) \\approx E_{val}(g^-) $$\n",
    "\n",
    "large K: Err val 接近 Err out, 但是 $ g^- $ 比 $ g_m $ 糟很多。\n",
    "\n",
    "small K: Err val 與 Err out 差異大, 但是 $ g^- \\approx g_m $\n",
    "\n",
    "一般用 $ K = \\frac{N}{5} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOOCV : Leave One Out Cross Validation\n",
    "\n",
    "只拿一個驗證資料 K=1, 例如第 n<sup>th</sup> 筆: $ D_{val}^{n} = \\big \\{ ( x_n, y_n ) \\big \\} $\n",
    "\n",
    "驗證錯誤 Validation Error = $ E_{val}^{n} ( g_n^- ) = err \\big( g_n^-(x_n), y_n \\big) = e_n $\n",
    "\n",
    "由單一筆資料做出的 $ e_n $ 可能接近 $ E_{out}(g) $ 嗎?   \n",
    "如果是將所有一筆一筆資料做出的眾多 $ e_n $ 平均，可能是接近 $ E_{out}(g) $ 的。\n",
    "\n",
    "Leave-One-Out Cross Validation estimate:\n",
    "\n",
    "$$ E_{LOOCV} (H, A) = \\frac{1}{N} \\sum_{n=1}^N = \\frac{1}{N} \\sum_{n=1}^N err \\big( g_n^- (x_n), y_n \\big) \\approx E_{out}(g) $$\n",
    "\n",
    "![img](imgs/c14-loocv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以 leave one out 的方式來選擇只有三個點 N=3 的 兩個 model (linear/constant) ，哪個好？  \n",
    "constant model 的 $ E_{LOOCV} $ 較小，比較好。\n",
    "\n",
    "#### Almost unbiased Estimate of $ E_{out}(g) $\n",
    "\n",
    "expected $ E_{LOOCV}(H,A) = avg \\ \\ E_{out} (N-1) = E_{out} (g^-) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disavantages of Leave-One-Out estimation\n",
    "\n",
    "#### 1. Computation\n",
    "\n",
    "N additional training per model, not always feasible in practice.\n",
    "\n",
    "例外: Linear Regression 有 leave-one-out 的 analytics solution, 所以是例外，可以很快求出。\n",
    "\n",
    "#### 2. Stability\n",
    "\n",
    "所以實務上少用 leave one out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V-Fold Cross Validation\n",
    "\n",
    "將 D 分成 V 份，例如 V=10 份, 再對每一個去做 validation, 剩下 9 份做 training。重複10次。  \n",
    "每一份資料都被當做過 validation data.\n",
    "\n",
    "$$ E_{CV} \\big( H, A \\big) = \\frac{1}{V} \\sum_{v=1}^V E_{val}^{(v)} (g_v^-) $$\n",
    "\n",
    "實務上常用 V = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Validation Tool\n",
    "\n",
    "V-Fold 通常比 單一驗證 好；如果 Computing Power 允許，使用較穩定的 V-Fold.\n",
    "\n",
    "5-Fold or 10-Fold 通常就不錯，不需要真的用到 Leave-One-Out."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
