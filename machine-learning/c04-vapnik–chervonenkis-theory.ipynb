{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hoeffding's Inequality\n",
    "\n",
    "D 母體中為橘色機率是 $ \\mu $  \n",
    "D 母體中為綠色機率是 $ 1 - \\mu $\n",
    "\n",
    "Sample 中為橘色機率是 $ v $  \n",
    "Sample 中為綠色機率是 $ 1 - v $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mathcal{P} \\big [ | v - \\mu | \\gt \\epsilon \\big] \\le \\frac{2}{e^{2 \\epsilon^2 N}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Probably Approximately Correct (P.A.C.)\n",
    "\n",
    "當 sample 數量 N 夠多時，樣本的橘色機率 $ v $ 與 母體的橘色機率 $ \\mu $ 差異小。\n",
    "\n",
    "$ \\epsilon $ : 錯誤容忍度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Let $ \\mu = 0.4, N=10, v \\le 0.1 $, What's the bound?\n",
    "\n",
    "$ v \\le 0.1 $ 代表 $ | v - \\mu | \\ge 0.3 $, 將 $ \\epsilon=0.3 $ 代入 $ 2 e^{-2 \\epsilon^2 N} = 2 \\times e^{-1.8} = 0.33 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formal Guarantee\n",
    "\n",
    "| symbol | symbol meaning |\n",
    "|-|:-:|\n",
    "| Unknown target function    | $ f: \\mathcal{X} \\to \\mathcal{Y} $ |\n",
    "| 抽出樣本的機率分佈         | P |\n",
    "| training data              | $ \\mathcal{D} : (x_1, y_1), \\cdots, (x_N, y_N) $ |\n",
    "| 在全部資料上的錯誤率 | $ E_{out}(h) = \\mathcal{E}_{x \\sim P} \\big[ h(x) \\ne f(x) \\big] $ |\n",
    "| 在樣本資料上的錯誤率 | $ E_{in}(h) = \\frac{1}{N} \\sum_{n=1}{N} \\big[ h(x_n) \\ne y_n \\big] $ |\n",
    "| ------------------------------ | ------------------------------------------------------- |\n",
    "\n",
    "$$ \\Bbb{P} \\big[ E_{in}(h) - E_{out}(h) \\gt \\epsilon \\big] \\le \\frac{2}{e^{2 \\epsilon^2 N}} = 2 \\exp( -2 \\epsilon^2 N ) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分為兩步驟:\n",
    "\n",
    "- 訓練 train, 確保 $ E_{in}(g) \\approx 0 $\n",
    "- 測試 test, 確保 $ E_{out}(g) \\approx E_{in}(g) $\n",
    "\n",
    "對固定的假設 h, 當資料 N 夠多時，$ E_{in}(h) \\approx E_{out}(h) $\n",
    "\n",
    "- 如果 $ E_{in}(h) $ 很小，挑出的函數 function:g 就與 f 幾乎一樣\n",
    "- 如果 $ E_{in}(h) $ 很大，挑出的函數 function:g 就與 f 很可能不一樣！\n",
    "\n",
    "### 這是對一個 hypothesis 做 Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning : 對多個 hypothesis 測試的情況\n",
    "\n",
    "B: Bad data, 拿 D 資料測試 hypothesis:h 時 $ E_{in}(h), E_{out}(h) $ 相差太大。\n",
    "\n",
    "$$\n",
    "\\begin{array}{l|c|c|c|c|c|l}\n",
    "    & D_1 & D_2 & D_3 & \\cdots & D_N & \\text{Hoeffding} \\\\\n",
    "\\hline\n",
    "h_1 & B   &     &     &        &     & \\Bbb{P}_D[\\text{Bad data}] \\le \\cdots \\\\\n",
    "h_2 &     & B   &     &        &     & \\Bbb{P}_D[\\text{Bad data}] \\le \\cdots \\\\\n",
    "h_3 &     &     &     &        & B   & \\Bbb{P}_D[\\text{Bad data}] \\le \\cdots \\\\\n",
    "\\hline\n",
    "\\text{ALL} & B & B &  &        & B   & ? \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "若是有許多個 h, 遇到 Bad Data (樣本資料D與母體相差太大) 就會被錯誤的排除。  \n",
    "出錯的機會就會增加。\n",
    "\n",
    "若是有 M 個 hypothesis, 所有出錯的機會是將 h1, h2, ..., hM 聯集，小於每單個 機率 加總。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\Bbb{P}_D [ \\text{Bad data} ] \n",
    "& = \\Bbb{P}_D [ \\text{Bad data for } h_1 & \\text{or Bad data for } h_2 & \\cdots & \\text{or Bad data for } h_M ] \\\\\n",
    "& = \\Bbb{P}_D [ \\text{Bad data for } h_1 & \\cup \\text{Bad data for } h_2 & \\cdots & \\cup \\text{Bad data for } h_M ] \\\\\n",
    "& \\le \\Bbb{P}_D[\\text{Bad data for } h_1] & + \\Bbb{P}_D[\\text{Bad data for } h_2] & + \\cdots & + \\Bbb{P}_D[\\text{Bad data for } h_M] & \\\\\n",
    "& \\le 2 \\exp(-2 \\epsilon^2 N) & + 2 \\exp(-2 \\epsilon^2 N) & + \\cdots & + 2 \\exp(-2 \\epsilon^2 N) \\\\\n",
    "& = 2 M \\exp(-2 \\epsilon^2 N)\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以若假設的數量 $ M = \\lVert H \\rVert $ **有限大**，而 D 資料量 N 足夠大，可以確保選中函數 g 的 $ E_{in}(g) \\approx E_{out}(g) $\n",
    "\n",
    "> 如果 假設的數量 無限大呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "$$ \\Bbb{P} \\big[ E_{in}(h) - E_{out}(h) \\gt \\epsilon \\big] \\le \\frac{2 M}{e^{2 \\epsilon^2 N}} = 2 M \\exp( -2 \\epsilon^2 N ) $$\n",
    "\n",
    "$ \\delta = 2 M \\exp( -2 \\epsilon^2 N ) $, 壞事發生的機率，樣本錯誤與母體錯誤相差太多\n",
    "\n",
    "$ \\epsilon \\lt E_{in}(h) - E_{out}(h) $, 樣本錯誤與母體錯誤相差太多, 相差太多的定義；亦即相似度是 $ \\epsilon $\n",
    "\n",
    "若希望 f, g 的相似度 $ \\epsilon = 0.1 $；  \n",
    "一共有 M = 100 個 hypothesis,  \n",
    "壞事發生的機率控制在 0.1 內 $ \\delta \\lt 0.1 $, 則需要至少多少個資料 N ？\n",
    "\n",
    "N = 415"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N, Effective(N)\n",
    "\n",
    "平面上有 N 個點，排在圓周上，可以找出多少條直線將這些點區隔成 +, - 兩邊。\n",
    "\n",
    "```\n",
    "...N ....Effective(N) <= 2^N\n",
    "   1               2       2  +, -\n",
    "   2               4       4  ++, -+, +-, --\n",
    "   3               8       8  +++, ++-, +-+, -++, --+, -+-, +--, ---\n",
    "   4              14      16  ++++, +++-, -+-+(無法成立), ...\n",
    "   5              22      32  ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dichotomies\n",
    "\n",
    "$ \\mathcal{H} = \\big \\{ \\text{ hypothesis } h: \\mathcal{X} \\to  \\{ 1, 0 \\} \\big \\} $, 二分法\n",
    "\n",
    "$ h \\big( x_1, x_2, \\cdots, x_N \\big) = \\big( h(x_1), h(x_2), \\cdots, h(x_N) \\big) \\in \\big \\{ 1, 0 \\big \\}^N $, h 將 $ x_1, x_2, \\cdots $ 轉換成 N 個 0或1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 成長函數 Growth Function\n",
    "\n",
    "$ m_H(N) = max_{x_1, \\cdots, x_n \\in X} \\big | \\ H(x_1, x_2, x_N ) $\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{l|c|c|c|c|c|l}\n",
    "N & m_H(N) & \\text{upper bound } 2^N \\\\\n",
    "\\hline\n",
    " 1 &  2 &  2 \\\\\n",
    " 2 &  4 &  4 \\\\\n",
    " 3 &  8 &  8 \\\\\n",
    " 4 & 14 & 16 \\\\ \n",
    " 5 & 22 & 32 \\\\ \n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Growth function of positive Rays\n",
    "\n",
    "Growth function of positive Rays: $ h(x) = sign(x-a) $\n",
    "\n",
    "```\n",
    "...-..-.....-..b...+.+...+....+.........+...\n",
    "```\n",
    "\n",
    "在一維的線條上，存在 N 點，a 將點分成兩邊。\n",
    "\n",
    "成長函數為: $ m_H(N) = N + 1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Growth function of positive Intervals\n",
    "\n",
    "Growth function of positive Interval: $ h(x) = \\begin{cases} \n",
    "+1, \\iff x \\in [l, r] \\\\\n",
    "-1, \\text{otherwise}\n",
    "\\end{cases} $\n",
    "\n",
    "```\n",
    "...-..-.....-..l...+.+...+.r...-.........-...\n",
    "```\n",
    "\n",
    "在一維的線條上，存在 N 點，a 將點分成兩邊。  \n",
    "從N點得 N+1 區域，任選兩區域放下 l,r；再加上所有都是 - 的狀況\n",
    "\n",
    "成長函數為: \n",
    "$ m_H(N) = \\binom{N+1}{2} + 1 = N^2 / 2 + N / 2 + 1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Growth function of Convex Set\n",
    "\n",
    "$ X \\in R^2 $\n",
    "\n",
    "Growth function of Convex Set: $ h(x) = \\begin{cases} \n",
    "+1, \\iff x \\text{ in convex region } \\\\\n",
    "-1, \\text{otherwise}\n",
    "\\end{cases} $\n",
    "\n",
    "```\n",
    "------------\n",
    "-----++-----\n",
    "----++++----\n",
    "---++++++---\n",
    "----+++-----\n",
    "------------\n",
    "```\n",
    "\n",
    "在二維的平面上，存在 N 點，能夠組成凸多邊形的點為 +, 凸多邊形外為 -\n",
    "\n",
    "成長函數為: \n",
    "$ m_H(N) = 2^N $\n",
    "\n",
    "對N個點來說，Convex Set 能夠形成最多的 dichotomy. we say **N inputs shattered by H**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break Point\n",
    "\n",
    "如果從 k 個開始，$ m_H(k) \\le 2^k $，k 就是 Break Point；  \n",
    "從 k 開始 k+1, k+2, ... 都是 break point。\n",
    "\n",
    "例如在 2D Perceptron 的狀況，$ m_H(4)=14 $,  \n",
    "從 4 開始，就都是 break point。\n",
    "\n",
    "所以可以去找 minimum break point. 知道 shatter 不再發生。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restriction of Break Point\n",
    "\n",
    "if minumum Break Point k = 2,  \n",
    "N = 1: every $ m_H(N) = 2 = 2^1 $  \n",
    "N = 2: every $ m_H(N) < 4 = 2^2 $, 所以最多是 3 種 dichotomies.  \n",
    "N = 3: every $ m_H(N) \\le 4 = 2^2 $, 最多是 4 種 dichotomies.  \n",
    "\n",
    "Maximum possible $ m_H(N) $ when N = 3, k = 2 ?\n",
    "\n",
    "4 dichotomies, shatter any two points? YES\n",
    "\n",
    "如下 N = 3 ($ x_1, x_2, x_3 $), 如果 k = 2, 那可以有哪些種的 dichotomies ? 6 種\n",
    "\n",
    "```\n",
    "  x1 x2 x3 : Okay ?\n",
    "   o  o  o : Y\n",
    "   o  o  x : Y\n",
    "   o  x  o : Y\n",
    "   x  o  o : Y\n",
    "  ---------:  \n",
    "   x  x  o : N\n",
    "   x  o  x : N\n",
    "   o  x  x : N\n",
    "   x  x  x : N\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上限函數 Bounding Function: B(N,k)\n",
    "\n",
    "bounding function B(N,k): 最多 dichotomies 的數量 $ m_H(N) $，當 break point = k.\n",
    "\n",
    "若用只有 {0,1} 元素，長度為 N 的向量來看，就是其中任何長度 k 的 sub-vector, 都不存在 shatter 的情況。\n",
    "\n",
    "Bounding Function 與 H 的細節無關，只要找到 break point k, 就可以限制 M。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Bounding Function\n",
    "\n",
    "$ B(N,k) = 2 a + b $  \n",
    "$ a + b \\le B(N-1, k) $  \n",
    "$ a \\le B(N-1, k-1) $  \n",
    "\n",
    "$ \\to B(N,k) \\le B(N-1,k) + B(N-1, k-1) $\n",
    "\n",
    "$$\n",
    "\\begin{array}{l|r|r|r|r|r|r|r}\n",
    "B(N,k), N \\backslash k & 1 & 2 & 3 & 4 & 5 & 6 & \\cdots \\\\\n",
    "\\hline\n",
    "1&   2&     2&     2&     2&     2&     2& \\\\\n",
    "2&   1&     3&     4&     4&     4&     4& \\\\\n",
    "3&   1&     4&     7&     8&     8&     8& \\\\\n",
    "4&   1&  \\le5&    11&    15&    16&    16& \\\\\n",
    "5&   1&  \\le6& \\le16& \\le26&    31&    32& \\\\\n",
    "6&   1&  \\le7& \\le22& \\le42& \\le57&    63& \\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding Function : The Theorem\n",
    "\n",
    "$$\n",
    "B(N,k) \\le \\sum_{i=0}^{k-1} \\binom{N}{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vapnik-Chervonenkis (VC) bound:\n",
    "\n",
    "$$\n",
    "\\mathbb{P} [ \\exists h \\in H s.t. | E_{in}(h) - E_{out}(h) | > \\epsilon ] \\le \n",
    "4 \\  m_H(2 N) \\  exp( - \\frac{1}{8} \\epsilon^2 N )\n",
    "$$\n",
    "\n",
    "- replace Eout by E'in\n",
    "- decompose H by kind\n",
    "- use Hoeffding without replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition : VC Dimension\n",
    "\n",
    "最大的 non-break point. 使得 $ m_H(N) = 2^N $, denoted as $ d_{vc}(\\mathcal{H}) $\n",
    "\n",
    "是最小的 break point: k 減 1。$ d_{vc}(\\mathcal{H}) = k - 1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example : 2D PLA\n",
    "\n",
    "線性可分的資料 D，經過 PLA 後可以確保 $ E_{in}(g) = 0 $\n",
    "\n",
    "另一方面，因為 $ d_{vc} = 3 $, 在樣本 N 夠大的時候，可以確保 $ E_{in}(g) \\approx E_{out}(g) $\n",
    "\n",
    "於是可知 $ E_{out}(g) \\approx 0 $\n",
    "\n",
    "> What about general PLA for x with 2+ features ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VC Dimension of Perceptrons\n",
    "\n",
    "1D perceptron (pos./neg. rays) : $ d_{vc} = 2 $  \n",
    "2D perceptron : $ d_{vc} = 3 $\n",
    "\n",
    "可能 xD perceptron : $ d_{vc} = x + 1 $ ?\n",
    "\n",
    "證明過程會利用兩個步驟:\n",
    "\n",
    "- Part 1. $ d_{vc} \\ge d + 1 $ : There are some d+1 inputs we can shatter.\n",
    "- Part 2. $ d_{vc} \\le d + 1 $ : We cannot shatter any set of d + 2 inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1.\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix} x_1^T\\\\x_2^T\\\\ \\cdots \\\\x_{d+1}^T \\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "1&0&0& \\cdots & 0 \\\\\n",
    "1&1&0& \\cdots & 0 \\\\\n",
    "\\vdots & & & & \\\\\n",
    "1&0&0& \\cdots & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "X 矩陣(有多加一個常數項), 為 invertible (RREF = I)\n",
    "\n",
    "對任一組解 $ \\vec{y} = \\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_{d+1} \\end{bmatrix} $ 都可以找到 $ \\vec{w} $ 使得  \n",
    "\n",
    "$ sign \\big( X \\vec{w} \\big) = \\vec{y} $, 而 X is invertible, 所以\n",
    "\n",
    "$ X \\vec{w} = \\vec{y} \\iff \\vec{w} = X^{-1} \\vec{y} $ \n",
    "\n",
    "得知 X can be shattered $ \\to d_{vc} \\ge d + 1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2.\n",
    "\n",
    "若在 2D 的例子裡，\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix} x_1^T\\\\x_2^T\\\\x_3^T\\\\x_4^T \\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "1&0&0 \\\\\n",
    "1&1&0 \\\\\n",
    "1&0&1 \\\\\n",
    "1&1&1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "```\n",
    "  x3(0,1)   x4(1,1)\n",
    "  x1(0,0)   x2(1,0)\n",
    "--------------------\n",
    "  + = w x3  ?\n",
    "  - = w x1  + = w x2 \n",
    "--------------------\n",
    "```\n",
    "\n",
    "線性組合關係  \n",
    "$ x_4 = x_2 + x_3 - x_1 $  \n",
    "$ w^T x_4 = w^T x_2 + w^T x_3 - w^T x_1 \\gt 0 $\n",
    "\n",
    "所以 $ w^T x_4 $ 只能是 +，因為 + + (--) 加在一起。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ w^T x_{d+2} = a_1 w^T x_1 + a_2 w^T x_2 + \\cdots + a_{d+1} w^T x_{d+1}, \\ \\ a_i $ 不全為零\n",
    "\n",
    "如此無法產生 $ \\big( sign(a_1)=+, sign(a_1)=+, \\cdots, sign(a_{d+1})=+, - \\big) $ 的情況\n",
    "\n",
    "所以 $ d_{vc} \\le d + 1 $\n",
    "\n",
    "> d + 1 就是 Perceptron 的維度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了 VC dimension 再來看 VC Bound\n",
    "\n",
    "$$\n",
    "\\mathbb{P} [ \\exists h \\in H s.t. | E_{in}(h) - E_{out}(h) | > \\epsilon ] \\le \n",
    "4 \\  m_H(2 N) \\  exp( - \\frac{1}{8} \\epsilon^2 N )\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{P} [ \\exists h \\in H s.t. | E_{in}(h) - E_{out}(h) | > \\epsilon ] \\le \n",
    "4 \\  (2 N)^{d_{vc}} \\  exp( - \\frac{1}{8} \\epsilon^2 N )\n",
    "$$\n",
    "\n",
    "#### 若 $ d_{vc} $ 小\n",
    "\n",
    "- 1. $ E_{out}(g) \\approx E_{in}(g) $ ? 兩者非常相似機率大嗎 ? **YES**\n",
    "- 2. 可以讓 $ E_{in}(g) $ 夠小嗎 ? **NO**\n",
    "\n",
    "#### 若 $ d_{vc} $ 大\n",
    "\n",
    "- 1. $ E_{out}(g) \\approx E_{in}(g) $ 兩者非常相似機率大嗎 ? **NO**\n",
    "- 2. 可以讓 $ E_{in}(g) $ 夠小嗎 ? **YES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalty for Model Complexity $ \\Omega(N, \\mathcal{H}, \\delta) $\n",
    "\n",
    "set $ \\delta = 4 \\  (2 N)^{d_{vc}} \\  exp( - \\frac{1}{8} \\epsilon^2 N ) $\n",
    "\n",
    "$ 1 - \\delta $ 就是 $ E_{in} - E_{out} \\le \\epsilon $ 接近的機率\n",
    "\n",
    "可以算出 \n",
    "\n",
    "$$\n",
    "\\epsilon = \\sqrt{ \\frac{8}{N} \\ln \\big( \\frac{4(2N)^{d_{vc}}}{\\delta} \\big) } \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{general error } \\Big| E_{in}(g) - E_{out}(g) \\Big| \\le \\sqrt{ \\frac{8}{N} \\ln \\big( \\frac{4(2N)^{d_{vc}}}{\\delta} \\big) }\n",
    "$$\n",
    "\n",
    "E out 被限制住:\n",
    "\n",
    "$$\n",
    "E_{in}(g) - \\sqrt{ \\frac{8}{N} \\ln \\big( \\frac{4(2N)^{d_{vc}}}{\\delta} \\big) }\n",
    "\\le E_{out}(g)\n",
    "\\le E_{in}(g) + \\sqrt{ \\frac{8}{N} \\ln \\big( \\frac{4(2N)^{d_{vc}}}{\\delta} \\big) }\n",
    "$$\n",
    "\n",
    "將 $ \\sqrt{\\cdots} $ 根號中的 $ \\frac{8}{N} \\ln \\big( \\frac{4(2N)^{d_{vc}}}{\\delta} \\big) $ 叫做 Penalty for model complexity. denoted : $ \\Omega(N, \\mathcal{H}, \\delta) $\n",
    "\n",
    "意即模型越複雜，就越容易偏離 E in 與 E out\n",
    "\n",
    "> Powerful H NOT always good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VC Bound : Sample Complexity\n",
    "\n",
    "$$ \\delta = 4 \\  (2 N)^{d_{vc}} \\  exp( - \\frac{1}{8} \\epsilon^2 N ) $$\n",
    "\n",
    "$$ \\Bbb{P} \\Big[ \\big| E_{in}(g) - E_{out}(g) \\big| \\lt \\epsilon \\Big] \\le \\delta $$\n",
    "\n",
    "若需要 E in out 相差超過 $ \\epsilon = 0.1 $ 以上 (10%) 的機會 $ \\delta = 0.1 $ (10%),  \n",
    "並 d_{vc} = 3\n",
    "\n",
    "希望做到 $ (2 N)^{d_{vc}} \\  exp( - \\frac{1}{8} \\epsilon^2 N ) \\le \\delta $\n",
    "\n",
    "```\n",
    "      N     bound\n",
    " -----------\n",
    "     100    2.82 x 10^7\n",
    "    1000    9.17 x 10^9\n",
    "  10,000    1.19 x 10^8\n",
    " 100,000    1.65 x 10^-38\n",
    "  29,300    9.99 x 10^-2\n",
    "```\n",
    "\n",
    "理論上: 需要 $ N \\approx 10000 \\times d_{vc} $\n",
    "\n",
    "實務上: 需要 $ N \\approx 10 \\times d_{vc} $, 就大概可以不錯。(因為loose bound)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
