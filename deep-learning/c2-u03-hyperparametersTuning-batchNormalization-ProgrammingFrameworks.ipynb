{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "priority: 1 > 2 > 3 > 4\n",
    "\n",
    "- 1 : $ \\alpha $ : learning rate\n",
    "- 2 : $ \\beta \\approx 0.9 $ : for momentum\n",
    "- 4 : $ \\beta_1 = 0.9 , \\beta_2 = 0.999 , \\epsilon = 10^{-8} $ : for Adam\n",
    "- 3 : number of layers\n",
    "- 2 : number of hidden units\n",
    "- 3 : learning rate decay\n",
    "- 2 : mini-batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用随机分布的参数，不要用固定区间的 grid 模式。可以对每个 hyperparameter 获得更多的参考点。\n",
    "\n",
    "获得第一批随机分布的参考点后，再对最优的区域，进行局部细化的随机测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale for hyperparameters\n",
    "\n",
    "随机的参数分布，有时不应该直接用原来数值进行随机分布。如\n",
    "\n",
    "learning rate: $ \\alpha $, 也许介于 0.0001 ~ 1 之间，需要不是这样的分布 \n",
    "\n",
    "```\n",
    "0.0001  0.1  0.2  0.3  0.4  0.5                       0.8  0.9  1.0\n",
    "|      x|    |    | x  |     |x                x       |    | x  |  \n",
    "```\n",
    "\n",
    "而是取对数后的分布\n",
    "\n",
    "```\n",
    "0.0001          0.001           0.01            0.1              1\n",
    "|      x         |         x     |x              |  x           x|\n",
    "```\n",
    "\n",
    "```\n",
    "# using numpy\n",
    "r = -4 * np.random.rand()\n",
    "alpha = 10^r\n",
    "```\n",
    "\n",
    "$ \n",
    "a = \\log_{10} 0.0001 = -4 \\\\\n",
    "b = \\log_{10} 1 = 0 \\\\\n",
    "r \\in [a, b] \\\\\n",
    "\\alpha = 10^r\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for exponentially weighted averages\n",
    "\n",
    "$\n",
    "\\beta \\in [ 0.9, 0.999 ] \\\\\n",
    "\\big( 1 - \\beta \\big) \\in [ 0.1, 0.0001 ]\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Norm\n",
    "\n",
    "在每一次 mini-batch 上，进行 $ Z^{[l ]}$ 的 Normalization，可以帮助每一层更独立地进行决策，较少收到别层的影响。  \n",
    "也有 \"一点\" regularization 的效果。\n",
    "\n",
    "这里会新增 parameter : $ \\gamma, \\beta $, (注意这个 beta 和 momentum, adam 的 beta 不同)\n",
    "\n",
    "最后使用 $ \\tilde{Z}^{[l]} $ 替代原来的 Z, 过程中 gamma, beta 内含了原来的 b 项，于是可以移除 b\n",
    "\n",
    "也有些做法是对 $ A^{[l ]} $ 进行 Normalization.\n",
    "\n",
    "注意在 test 的时候，没有 mini-batch，拿最后 training 获得的 mu, sigma (may use exponential weight average) 用在单个sample。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{cases}\n",
    "\\mu & = \\frac{1}{m} \\sum_i Z^{[l](i)} \\\\\n",
    "\\sigma^2 & = \\frac{1}{m} \\sum_i \\big( Z^{[l]} - \\mu \\big)^2 \\\\\n",
    "Z_{\\text{norm}}^{[l]} & = \\frac{Z^{[l]} - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\\\\n",
    "\\tilde{Z}^{[l]} & = \\gamma Z_{\\text{norm}}^{[l]} + \\beta \n",
    "\\end{cases}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3cv",
   "language": "python",
   "name": "p3cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
