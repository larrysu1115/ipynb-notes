{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic CNNs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet - 5\n",
    "\n",
    "number of parameters: ~60 K \n",
    "\n",
    "`(5*5*6+5*5*6*16+400*120+120*84+84*10)`\n",
    "\n",
    "用 conv 接著 pool 形成一個 layer.\n",
    "\n",
    "```code\n",
    "               |   dimension       |   setting \n",
    " X:INPUT       |   32 x 32 x 1     | CONV, f:5, s:1, #:6\n",
    " C1            |   28 x 28 x  6    | POOL:AVG, f:2, s:2 \n",
    " S2            |   14 x 14 x  6    | CONV, f:5, s:1, #:16\n",
    " C3            |   10 x 10 x 16    | POOL:AVG, f:2, s:2  \n",
    " S4            |    5 x  5 x 16    | FC, 400 -> 120\n",
    " C5            |  120              | FC, 120 ->  84\n",
    " F6            |   84              | SOFTMAX, 84 ->  10\n",
    " Y             |   10              |\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet\n",
    "\n",
    "number of parameters: ~60 M\n",
    "\n",
    "`11*11*3*96+5*5*96*256+3*3*256*384+3*3*256*384+3*3*384*256+6*6*256*4096+4096*4096+4096*1000 = 61,925,408`\n",
    "\n",
    "```code\n",
    "X:INPUT    |  227 x 227 x   3   | CONV     ~ f:11, s:4\n",
    "C1         |   55 x  55 x  96   | POOL-MAX ~ f:3, s:2 \n",
    "P2         |   27 x  27 x  96   | CONV     ~ f:5, SAME\n",
    "C3         |   27 x  27 x 256   | POOL-MAX ~ f:3, s:2 \n",
    "P4         |   13 x  13 x 256   | CONV     ~ f:3, SAME\n",
    "C5         |   13 x  13 x 384   | CONV     ~ f:3, SAME\n",
    "C6         |   13 x  13 x 384   | CONV     ~ f:3, SAME\n",
    "C7         |   13 x  13 x 256   | POOL-MAX ~ f:3, s:2\n",
    "P8         |    6 x   6 x 256   | FC       ~ 9216 -> 4096\n",
    "F9         | 4096               | FC       ~ 4096 -> 4096\n",
    "F10        | 4096               | SOFTMAX  ~ 4096 -> 1000\n",
    "Y          | 1000\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-16 Network\n",
    "\n",
    "number of parameters: ~138 M\n",
    "\n",
    "```code\n",
    "C: CONV, f:3, SAME\n",
    "P: MAX POOL, f:2, s:2\n",
    "\n",
    "C#64 x 2 : run Conv with 64 filters for 2 times\n",
    "\n",
    "X:INPUT   |  224 x 224 x   3   | C#64 x 2\n",
    "C3        |  224 x 224 x  64   | P\n",
    "P4        |  112 x 112 x  64   | C#128 x 2 \n",
    "C6        |  112 x 112 x 128   | P\n",
    "P7        |   56 x  56 x 128   | C#256 x 3\n",
    "C10       |   56 x  56 x 256   | P\n",
    "P11       |   28 x  28 x 256   | C#512 x 3\n",
    "C14       |   28 x  28 x 512   | P\n",
    "P15       |   14 x  14 x 512   | C#512 x 3\n",
    "C18       |   14 x  14 x 512   | P\n",
    "P19       |    7 x   7 x 512   | FC\n",
    "F20       | 4096               | FC\n",
    "F21       | 4096               | SOFTMAX\n",
    "Y         | 1000               |\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual block\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "a^{[l+2]} & = g \\big( z^{[l+2]} + \\underbrace{a^{[l]}}_{\\text{residual block}} \\big) \\\\\n",
    "& = g \\big( w^{[l+2]} \\ a^{[l+1]} + b^{[l+2]} + a^{[l]} \\big)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "若沒有 residual block, 而 $ w^{[l+2]}, b^{[l+2]} $ 逼近於 0, 最佳化程序就不易找回原來的 identity : $ a^{[l]} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One by one convolution\n",
    "\n",
    "用 $ 1 \\times 1 \\times n_c $ 的 filter 進行 convolution\n",
    "\n",
    "也叫做 network in network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception Network\n",
    "\n",
    "使用各種不同形式的 CONV operation，設計好輸出一樣的 $ \\big( n_h, n_w, ? \\big) $ ，將個別結果堆疊 stack 起來，形成該層的結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem of computation cost:\n",
    "\n",
    "```\n",
    "INPUT   28 x28 x192\n",
    "   >>> CONV f:5, #:32, SAME >>>\n",
    "OUTPUT  28 x28 x 32\n",
    "```\n",
    "\n",
    "這樣的計算，乘法需要 `28 * 28 * 32 * (5 * 5 * 192)` = ~ 120M 次乘法。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottleneck layer\n",
    "\n",
    "```\n",
    "INPUT  28 x 28 x 192\n",
    "    >>> CONV f:1, #:16, SAME\n",
    "C1     28 x 28 x 16            <<< Bottleneck Layer\n",
    "    >>> CONV f:5, #:32, SAME\n",
    "C2     28 x 28 x 32\n",
    "```\n",
    "\n",
    "則需要的乘法計算次數:\n",
    "\n",
    "```\n",
    "(1*1*192) * (28*28*16) + (5*5*16) * (28*28*32) = ~12,443,648\n",
    "```\n",
    "\n",
    "透過 bottleneck layer, 減少了10倍運算 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception module\n",
    "\n",
    "利用重複的 inception module, 成為 inception network,  \n",
    "單一的 inception module 構成如下:\n",
    "\n",
    "```\n",
    "                   ------------------> CONV 1x1 #64 --> 28x28x 64\n",
    "Prev Activations:  --> CONV 1x1#96 --> CONV 3x3#128 --> 28x28x128\n",
    "28 x 28 x 192      --> CONV 1x1#16 --> CONV 5x5# 32 --> 28x28x 32\n",
    "                   --> MAXP 3x3    --> CONV 1x1# 32 --> 28x28x 32\n",
    "                   \n",
    "將結果 stack 起來，形成 result: 28x28x (64+128+32+32)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "有許多成熟的 NN 已經 open source, 直接可以用它的結構，以及 weights 來做 transfer learning.\n",
    "\n",
    "通常會比自己從頭開始訓練的結果好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Data Augmentation\n",
    "\n",
    "- 左右顛倒\n",
    "- Random Crop (不是很完美的辦法，但通常也有幫助)\n",
    "- Rotation\n",
    "- Shearing\n",
    "- Local warping\n",
    "- Color Shifting ( 如 R:+20, G:-20, B:+20 ) 模擬因為光線變化，產生的色彩差異。\n",
    "- PCA color augmentation (from AlexNet paper)\n",
    "\n",
    "實作上，可以用 A:CPU+Thread 做 data augmentation (distortion), 另外 B:CPU+Thread 做 mini-batch training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for doing well on benchmarks\n",
    "\n",
    "- Train several networks independently and average their outputs $ \\hat{y} $\n",
    "- Multi-crop at test time: Run classifier on multiple versions of test image and average output, such as \"10-Crop\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3cv",
   "language": "python",
   "name": "p3cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
